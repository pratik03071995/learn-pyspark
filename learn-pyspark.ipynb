{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/18 12:48:01 WARN Utils: Your hostname, Pratiks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.43 instead (on interface en0)\n",
      "24/02/18 12:48:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.0\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.15\n",
      "Branch HEAD\n",
      "Compiled by user ubuntu on 2023-09-09T01:53:20Z\n",
      "Revision ce5ddad990373636e94071e7cef2f31021add07b\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/18 12:48:07 WARN Utils: Your hostname, Pratiks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.43 instead (on interface en0)\n",
      "24/02/18 12:48:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/18 12:48:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Data Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
    "data = spark.read.csv('sample_data_test.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- Customer Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Phone 1: string (nullable = true)\n",
      " |-- Phone 2: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Subscription Date: date (nullable = true)\n",
      " |-- Website: string (nullable = true)\n",
      "\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|Index|    Customer Id|First Name|Last Name|             Company|            City|             Country|             Phone 1|             Phone 2|               Email|Subscription Date|             Website|\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|    1|4962fdbE6Bfee6D|       Pam|   Sparks|        Patel-Deleon|      Blakemouth|British Indian Oc...|    267-243-9490x035|    480-078-0535x889|nicolas00@faulkne...|       2020-11-29| https://nelson.com/|\n",
      "|    2|9b12Ae76fdBc9bE|      Gina|    Rocha|Acosta, Paul and ...|East Lynnchester|          Costa Rica|        027.142.0940|+1-752-593-4777x0...|  yfarley@morgan.com|       2021-01-03|https://pineda-ro...|\n",
      "|    3|39edFd2F60C85BC|   Kristie|    Greer|           Ochoa PLC|     West Pamela|             Ecuador|+1-049-168-7497x5053|     +1-311-216-7855|jennyhayden@petty...|       2021-06-20|https://mckinney....|\n",
      "|    4|Fa42AE6a9aD39cE|    Arthur|   Fields|          Moyer-Wang|    East Belinda|         Afghanistan|001-653-754-7486x...|    521-630-3858x953|igrimes@ruiz-todd...|       2020-02-13|https://dominguez...|\n",
      "|    5|F5702Edae925F1D|  Michelle|  Blevins|       Shah and Sons|      West Jared|    Marshall Islands|          8735278329|   (633)283-6034x500|diamondcarter@jor...|       2020-10-20|http://murillo-ry...|\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the schema of the dataset\n",
    "data.printSchema()\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the dataset\n",
    "print(\"Total number of rows:\", data.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after cleaning: 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaned_data = data.dropna()\n",
    "\n",
    "# Count the number of rows after cleaning\n",
    "print(\"Total number of rows after cleaning:\", cleaned_data.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide Transformation Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Country|count|\n",
      "+--------------------+-----+\n",
      "|                Chad| 8134|\n",
      "|            Anguilla| 8128|\n",
      "|            Paraguay| 8130|\n",
      "|               Macao| 8247|\n",
      "|Heard Island and ...| 8082|\n",
      "|               Yemen| 8058|\n",
      "|             Senegal| 8181|\n",
      "|             Tokelau| 8196|\n",
      "|              Sweden| 8110|\n",
      "|            Kiribati| 8210|\n",
      "|French Southern T...| 8091|\n",
      "|              Guyana| 8068|\n",
      "|         Philippines| 8227|\n",
      "|             Eritrea| 7974|\n",
      "|              Jersey| 8011|\n",
      "|            Djibouti| 8286|\n",
      "|               Tonga| 8160|\n",
      "|      Norfolk Island| 8113|\n",
      "|            Malaysia| 8166|\n",
      "|           Singapore| 8143|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Wide transformation example\n",
    "wide_df = data.groupBy(\"Country\").count()\n",
    "print(\"Wide Transformation Result:\")\n",
    "wide_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrow Transformation Result:\n",
      "+----------+---------+\n",
      "|First Name|Last Name|\n",
      "+----------+---------+\n",
      "|      Gina|    Rocha|\n",
      "|  Margaret|   Rogers|\n",
      "|     Tanya| Franklin|\n",
      "|     Steve|Valentine|\n",
      "|     Tracy|   Briggs|\n",
      "|  Benjamin|     Gray|\n",
      "|    Colton| Mcintyre|\n",
      "|      Gail|      Ray|\n",
      "|    Brandi|Contreras|\n",
      "|      Troy|  Sellers|\n",
      "|     Robin|    Black|\n",
      "|     Nancy|    Brown|\n",
      "|    Ernest| Mcmillan|\n",
      "|   Jasmine|   Norman|\n",
      "|     Sonya|   Turner|\n",
      "|     Jorge|    Mejia|\n",
      "|     Chris|   Walter|\n",
      "|     Penny|  Carlson|\n",
      "|       Jay|   Booker|\n",
      "|     David|  Lindsey|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Narrow transformation example\n",
    "narrow_df = data.filter(data[\"Country\"] == \"Costa Rica\").select(\"First Name\", \"Last Name\")\n",
    "# Show results\n",
    "print(\"Narrow Transformation Result:\")\n",
    "narrow_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 8\n"
     ]
    }
   ],
   "source": [
    "# Get the number of partitions\n",
    "num_partitions = data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions:\", num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions after repartitioning: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================>                                    (3 + 5) / 8]\r"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "data = data.repartition(10)  # Repartitioning to 10 partitions\n",
    "\n",
    "# Get the number of partitions after repartitioning\n",
    "num_partitions_after_repartition = data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions after repartitioning:\", num_partitions_after_repartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions after coalesce: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=====================>                                    (3 + 5) / 8]\r"
     ]
    }
   ],
   "source": [
    "# Coalesce data into 5 partitions\n",
    "data = data.coalesce(5)\n",
    "# Get the number of partitions after repartitioning\n",
    "num_partitions_after_coalesce = data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions after coalesce:\", num_partitions_after_coalesce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
