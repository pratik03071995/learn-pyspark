{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.0\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.15\n",
      "Branch HEAD\n",
      "Compiled by user ubuntu on 2023-09-09T01:53:20Z\n",
      "Revision ce5ddad990373636e94071e7cef2f31021add07b\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/18 14:44:16 WARN Utils: Your hostname, Pratiks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.43 instead (on interface en0)\n",
      "24/02/18 14:44:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/18 14:44:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Data Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
    "data = spark.read.csv('sample_data_test.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- Customer Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Phone 1: string (nullable = true)\n",
      " |-- Phone 2: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Subscription Date: date (nullable = true)\n",
      " |-- Website: string (nullable = true)\n",
      "\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|Index|    Customer Id|First Name|Last Name|             Company|            City|             Country|             Phone 1|             Phone 2|               Email|Subscription Date|             Website|\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|    1|4962fdbE6Bfee6D|       Pam|   Sparks|        Patel-Deleon|      Blakemouth|British Indian Oc...|    267-243-9490x035|    480-078-0535x889|nicolas00@faulkne...|       2020-11-29| https://nelson.com/|\n",
      "|    2|9b12Ae76fdBc9bE|      Gina|    Rocha|Acosta, Paul and ...|East Lynnchester|          Costa Rica|        027.142.0940|+1-752-593-4777x0...|  yfarley@morgan.com|       2021-01-03|https://pineda-ro...|\n",
      "|    3|39edFd2F60C85BC|   Kristie|    Greer|           Ochoa PLC|     West Pamela|             Ecuador|+1-049-168-7497x5053|     +1-311-216-7855|jennyhayden@petty...|       2021-06-20|https://mckinney....|\n",
      "|    4|Fa42AE6a9aD39cE|    Arthur|   Fields|          Moyer-Wang|    East Belinda|         Afghanistan|001-653-754-7486x...|    521-630-3858x953|igrimes@ruiz-todd...|       2020-02-13|https://dominguez...|\n",
      "|    5|F5702Edae925F1D|  Michelle|  Blevins|       Shah and Sons|      West Jared|    Marshall Islands|          8735278329|   (633)283-6034x500|diamondcarter@jor...|       2020-10-20|http://murillo-ry...|\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the schema of the dataset\n",
    "data.printSchema()\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the dataset\n",
    "print(\"Total number of rows:\", data.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after cleaning: 2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaned_data = data.dropna()\n",
    "\n",
    "# Count the number of rows after cleaning\n",
    "print(\"Total number of rows after cleaning:\", cleaned_data.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide Transformation Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Country|count|\n",
      "+--------------------+-----+\n",
      "|                Chad| 8134|\n",
      "|            Anguilla| 8128|\n",
      "|            Paraguay| 8130|\n",
      "|               Macao| 8247|\n",
      "|Heard Island and ...| 8082|\n",
      "|               Yemen| 8058|\n",
      "|             Senegal| 8181|\n",
      "|             Tokelau| 8196|\n",
      "|              Sweden| 8110|\n",
      "|            Kiribati| 8210|\n",
      "|French Southern T...| 8091|\n",
      "|              Guyana| 8068|\n",
      "|         Philippines| 8227|\n",
      "|             Eritrea| 7974|\n",
      "|              Jersey| 8011|\n",
      "|            Djibouti| 8286|\n",
      "|               Tonga| 8160|\n",
      "|      Norfolk Island| 8113|\n",
      "|            Malaysia| 8166|\n",
      "|           Singapore| 8143|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Wide transformation example\n",
    "wide_df = data.groupBy(\"Country\").count()\n",
    "print(\"Wide Transformation Result:\")\n",
    "wide_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrow Transformation Result:\n",
      "+----------+---------+\n",
      "|First Name|Last Name|\n",
      "+----------+---------+\n",
      "|      Gina|    Rocha|\n",
      "|  Margaret|   Rogers|\n",
      "|     Tanya| Franklin|\n",
      "|     Steve|Valentine|\n",
      "|     Tracy|   Briggs|\n",
      "|  Benjamin|     Gray|\n",
      "|    Colton| Mcintyre|\n",
      "|      Gail|      Ray|\n",
      "|    Brandi|Contreras|\n",
      "|      Troy|  Sellers|\n",
      "|     Robin|    Black|\n",
      "|     Nancy|    Brown|\n",
      "|    Ernest| Mcmillan|\n",
      "|   Jasmine|   Norman|\n",
      "|     Sonya|   Turner|\n",
      "|     Jorge|    Mejia|\n",
      "|     Chris|   Walter|\n",
      "|     Penny|  Carlson|\n",
      "|       Jay|   Booker|\n",
      "|     David|  Lindsey|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Narrow transformation example\n",
    "narrow_df = data.filter(data[\"Country\"] == \"Costa Rica\").select(\"First Name\", \"Last Name\")\n",
    "# Show results\n",
    "print(\"Narrow Transformation Result:\")\n",
    "narrow_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repartition and Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 8\n"
     ]
    }
   ],
   "source": [
    "# Get the number of partitions\n",
    "num_partitions = data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions:\", num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions after repartitioning: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================>                                    (3 + 5) / 8]\r"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "data = data.repartition(10)  # Repartitioning to 10 partitions\n",
    "\n",
    "# Get the number of partitions after repartitioning\n",
    "num_partitions_after_repartition = data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions after repartitioning:\", num_partitions_after_repartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions after coalesce: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=====================>                                    (3 + 5) / 8]\r"
     ]
    }
   ],
   "source": [
    "# Coalesce data into 5 partitions\n",
    "data = data.coalesce(5)\n",
    "# Get the number of partitions after repartitioning\n",
    "num_partitions_after_coalesce = data.rdd.getNumPartitions()\n",
    "print(\"Number of partitions after coalesce:\", num_partitions_after_coalesce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistence and Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/18 13:52:16 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Index: int, Customer Id: string, First Name: string, Last Name: string, Company: string, City: string, Country: string, Phone 1: string, Phone 2: string, Email: string, Subscription Date: date, Website: string]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache DataFrame\n",
    "# cache automatically set storage to memory only \n",
    "data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 2000000\n",
      "+------+---------------+----------+----------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "| Index|    Customer Id|First Name| Last Name|             Company|           City|             Country|             Phone 1|             Phone 2|               Email|Subscription Date|             Website|\n",
      "+------+---------------+----------+----------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "| 20198|2240834Aa9c96aB|  Terrance|    Parker|Montoya, Mckenzie...| Robertsonmouth|               Haiti| +1-748-802-4792x351|001-835-071-8076x100|xellis@booth-tuck...|       2020-09-09| https://stokes.com/|\n",
      "|180599|dDF06AdcCbA9Fc4|   Allison|     Berry|         Koch-Pruitt|    Hooperburgh|        Cook Islands|001-518-005-1460x297| +1-846-115-0465x242|daughertylarry@sh...|       2020-08-20|  http://berger.com/|\n",
      "| 45814|74d1E2B58b31DC0|      Jeff|      Koch|      Mills-Morrison|    New Annette|      Cayman Islands|       (096)204-7724|  341-066-6816x04302|allison51@baldwin...|       2020-07-28|https://www.carro...|\n",
      "| 39895|9060bA9aC2Ed0C7|     Paula|   Harrell|        Farley-Myers|   Williamville|             Romania|001-730-470-7443x...| (266)908-7187x09585|clintonbarnes@qui...|       2020-12-08|https://castro.info/|\n",
      "|224685|aBE6B0Ebd7E142D|     Edwin|   Pollard|           Chase Ltd|       Johnbury|  Russian Federation|001-458-944-6629x...|    523-640-2789x368|ritamccormick@ell...|       2022-02-02|http://www.stanto...|\n",
      "|218857|E3c3584bdF933Dd| Dominique|     Ochoa| Foster, Shea and Le|    Lake Miguel|            Bulgaria|001-794-644-4998x...|       (446)917-3367| eugene21@cortez.biz|       2022-04-01|https://www.andre...|\n",
      "|143958|fE4E059959Ccadd|     Marco|   Bernard|           Kent-Holt|   West Timstad|Cocos (Keeling) I...|   953.134.1262x5331|  (429)105-1379x1306|dickersonvernon@m...|       2022-02-13|http://www.terry....|\n",
      "| 25956|Ef88404aCAfF82a|  Jonathan| Dickerson|           Poole Inc|  Castanedastad|          San Marino|          5970656452|001-365-049-5051x547|geoffreysweeney@v...|       2022-02-15|https://montgomer...|\n",
      "|234444|aeB2b29eFf6629E| Elizabeth|     Evans|     Dominguez Group|     Meyersfort|United States of ...|    489-242-8718x630|        445.528.0642| carrie89@giles.info|       2021-08-03|http://barber-cop...|\n",
      "| 79019|C0A03E7Dd0171a9|      Levi|   Harrell|Flynn, Hahn and S...|       East Tim|            Ethiopia|  040-143-1049x39657| +1-847-076-2375x535|stanley98@stevens...|       2022-01-20|http://www.brady....|\n",
      "|198298|bECb6aCB84AbbDB|    Adrian|     Mayer|    Williams-Shaffer|  North Maxland|           Nicaragua|          7674238033|        752.724.6504|wvaughan@carlson.com|       2020-08-23|https://simmons-k...|\n",
      "|223084|83e741ea9CE1E01|     Megan|Williamson|        Johnson-Frye|   Franklinfort|British Indian Oc...|  454.824.3831x16564|+1-047-005-2977x8...|anthonywebster@sp...|       2020-02-27|http://www.griffi...|\n",
      "| 54307|D9AA5aCAcF6FFF1|      Ross|  Whitaker|Pena, Cordova and...|      Walshport|Saint Vincent and...|001-534-864-9375x...|  344-846-5964x33296|  pbender@vance.info|       2020-07-16|https://www.baile...|\n",
      "| 49711|DEaDdDECcB39c78|   Vanessa|  Chambers|       Spencer-Singh| Navarrochester|             Belgium|        233-510-5642|        707-472-0255|     rdowns@york.com|       2020-12-26|https://www.mccla...|\n",
      "|211245|cAEC908EB0fdf2e|    Miguel|     Avery|      Melton-Frazier|       Port Dan|            Pakistan|001-452-552-6139x650|          1930315772|utapia@nielsen-ma...|       2022-01-26|http://www.barrer...|\n",
      "| 92314|eC7AFCEfbe0BfE2|      Kent|      Kirk|Ritter, Mckee and...| North Adrienne|     Kyrgyz Republic|  919-719-1242x68863|   331.783.6864x9829|barnettjordan@ban...|       2021-11-11|    http://mayo.com/|\n",
      "|106526|ebFCa8A835C93B3|     Isaac|     House|      Humphrey Group|      East Anne|            Honduras|        097.644.1338|001-338-797-5854x...|  jerry63@benson.com|       2021-06-01|http://reese-ponc...|\n",
      "|211930|888b66473B50Eb3|      Lori|  Marshall|        Newton-Doyle|    Juarezburgh|               Nepal| (749)938-4805x94428|          9678115971|   jane11@norman.com|       2021-04-09|http://andersen.com/|\n",
      "|149800|DCcF48418A2d222|     Ebony|    Santos|      Singleton-Mays|Port Carlyburgh|      Cayman Islands|+1-767-695-2840x4369|001-370-679-4075x...|  jake16@barajas.biz|       2020-08-27|  http://grimes.com/|\n",
      "|   497|4cfb1E880732AAC|    Teresa|  Mitchell|         Barnett PLC|     Farleybury|               Malta|        758.379.7228|          2938376914|  wnoble@preston.com|       2020-06-15|http://www.jennin...|\n",
      "+------+---------------+----------+----------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example actions to trigger caching\n",
    "# Count action\n",
    "count = data.count()\n",
    "print(\"Count:\", count)\n",
    "\n",
    "# Show action\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/18 13:51:25 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Index: int, Customer Id: string, First Name: string, Last Name: string, Company: string, City: string, Country: string, Phone 1: string, Phone 2: string, Email: string, Subscription Date: date, Website: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "# storage levels MEMORY_ONLY,MEMORY_AND_DISK, MEMORY_ONLY_SER, MEMORY_AND_DISK_SER, DISK_ONLY, MEMORY_ONLY_2,MEMORY_AND_DISK_2\n",
    "data.persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Index: int, Customer Id: string, First Name: string, Last Name: string, Company: string, City: string, Country: string, Phone 1: string, Phone 2: string, Email: string, Subscription Date: date, Website: string]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD Unpersist\n",
    "# PySpark automatically monitors every persist() and cache() calls you make and it checks usage on each node and drops persisted data if not used or by using least-recently-used (LRU) algorithm\n",
    "data.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast Variables and Accumulator Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a broadcast variable\n",
    "broadcast_var = spark.sparkContext.broadcast({\"USA\": \"United States\", \"UK\": \"United Kingdom\"})\n",
    "# Create an accumulator variable\n",
    "accum = spark.sparkContext.accumulator(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Romania records: 8137\n"
     ]
    }
   ],
   "source": [
    "# Create an accumulator variable\n",
    "accum = spark.sparkContext.accumulator(0)\n",
    "\n",
    "# Map function to count USA records and update accumulator\n",
    "# Need to increase executor and driver memory to compute large data accumulator\n",
    "def count_usa(record):\n",
    "    global accum\n",
    "    if record[\"Country\"] == \"Romania\":\n",
    "        accum += 1\n",
    "    return record\n",
    "\n",
    "# Apply map function to count USA records\n",
    "usa_records = data.rdd.map(count_usa)\n",
    "\n",
    "# Perform an action to trigger the map transformation\n",
    "usa_records.collect()\n",
    "\n",
    "# Get the value of the accumulator\n",
    "print(\"Number of Romania records:\", accum.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|Index|    Customer Id|First Name|Last Name|             Company|            City|             Country|             Phone 1|             Phone 2|               Email|Subscription Date|             Website|\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|    1|4962fdbE6Bfee6D|       Pam|   Sparks|        Patel-Deleon|      Blakemouth|British Indian Oc...|    267-243-9490x035|    480-078-0535x889|nicolas00@faulkne...|       2020-11-29| https://nelson.com/|\n",
      "|    2|9b12Ae76fdBc9bE|      Gina|    Rocha|Acosta, Paul and ...|East Lynnchester|          Costa Rica|        027.142.0940|+1-752-593-4777x0...|  yfarley@morgan.com|       2021-01-03|https://pineda-ro...|\n",
      "|    3|39edFd2F60C85BC|   Kristie|    Greer|           Ochoa PLC|     West Pamela|             Ecuador|+1-049-168-7497x5053|     +1-311-216-7855|jennyhayden@petty...|       2021-06-20|https://mckinney....|\n",
      "|    4|Fa42AE6a9aD39cE|    Arthur|   Fields|          Moyer-Wang|    East Belinda|         Afghanistan|001-653-754-7486x...|    521-630-3858x953|igrimes@ruiz-todd...|       2020-02-13|https://dominguez...|\n",
      "|    5|F5702Edae925F1D|  Michelle|  Blevins|       Shah and Sons|      West Jared|    Marshall Islands|          8735278329|   (633)283-6034x500|diamondcarter@jor...|       2020-10-20|http://murillo-ry...|\n",
      "+-----+---------------+----------+---------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a broadcast variable\n",
    "broadcast_var = spark.sparkContext.broadcast({\"USA\": \"United States\", \"UK\": \"United Kingdom\"})\n",
    "\n",
    "# Use broadcast variable to convert country names\n",
    "def convert_country_name(record):\n",
    "    global broadcast_var\n",
    "    country = record[\"Country\"]\n",
    "    if country in broadcast_var.value:\n",
    "        record[\"Country\"] = broadcast_var.value[country]\n",
    "    return record\n",
    "\n",
    "# Apply map function to convert country names\n",
    "converted_df = data.rdd.map(convert_country_name).toDF()\n",
    "\n",
    "# Show the DataFrame with converted country names\n",
    "converted_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
